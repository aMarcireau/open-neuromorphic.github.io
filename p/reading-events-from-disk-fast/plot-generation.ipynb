{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from expelliarmus import Wizard\n",
    "import aedat\n",
    "import h5py\n",
    "import numpy as np\n",
    "import timeit\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "import loris\n",
    "import brotli\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fname = \"driving_sample\"\n",
    "fname = \"construction\"  # use this one if you want to include aedat and eventstream benchmarks\n",
    "\n",
    "# where to download and generate all the benchmark data\n",
    "folder = Path(\"data/file-benchmark\")\n",
    "folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# key is the name of the encoding, value is the file name ending\n",
    "extension_map = {\n",
    "    \"aedat\": \".aedat4\",\n",
    "    \"dat\": \".dat\",\n",
    "    \"evt2\": \"_evt2.raw\",\n",
    "    \"evt3\": \"_evt3.raw\",\n",
    "    \"hdf5\": \".hdf5\",\n",
    "    \"hdf5_lzf\": \"_lzf.hdf5\",\n",
    "    \"hdf5_gzip\": \"_gzip.hdf5\",\n",
    "    \"numpy\": \".npy\",\n",
    "    \"eventstream\": \".es\",\n",
    "    \"brotli\": \".bin.br\",\n",
    "}\n",
    "get_fpath = lambda encoding: f\"{folder}/{fname}{extension_map[encoding]}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the 'base' files\n",
    "These are the files with the original data, which will be loaded and then converted to all other formats under test. Currently you can choose between events from a Prophesee raw evt3 or an aedat4 sample file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_file_from_url(file_path, url):\n",
    "    print(f\"Downloading file to {file_path}... \")\n",
    "    r = requests.get(\n",
    "        url,\n",
    "        allow_redirects=True,\n",
    "    )\n",
    "    open(file_path, \"wb\").write(r.content)\n",
    "    print(\"done!\")\n",
    "\n",
    "\n",
    "if fname == \"driving_sample\":\n",
    "    fpath = get_fpath(\"evt3\")\n",
    "    if not Path(fpath).is_file():\n",
    "        download_file_from_url(\n",
    "            fpath, \"https://dataset.prophesee.ai/index.php/s/nVcLLdWAnNzrmII/download\"\n",
    "        )\n",
    "    wizard = Wizard(encoding=\"evt3\")\n",
    "    data = wizard.read(fpath)\n",
    "\n",
    "\n",
    "if fname == \"construction\":\n",
    "    aedat_fpath = get_fpath(\"aedat\")\n",
    "    if not Path(aedat_fpath).is_file():\n",
    "        download_file_from_url(\n",
    "            aedat_fpath,\n",
    "            \"https://cloudstor.aarnet.edu.au/plus/s/ORQ2oOz9NfwiHLZ/download?path=%2F&files=construction.aedat4\",\n",
    "        )\n",
    "\n",
    "    es_fpath = get_fpath(\"eventstream\")\n",
    "    if not Path(es_fpath).is_file():\n",
    "        download_file_from_url(\n",
    "            es_fpath,\n",
    "            \"https://cloudstor.aarnet.edu.au/plus/s/ORQ2oOz9NfwiHLZ/download?path=%2F&files=construction.es\",\n",
    "        )\n",
    "\n",
    "    decoder = aedat.Decoder(aedat_fpath)\n",
    "    events = np.concatenate(\n",
    "        [packet[\"events\"] for packet in decoder if \"events\" in packet]\n",
    "    )\n",
    "    data = events.astype(\n",
    "        np.dtype([(\"t\", \"<i8\"), (\"x\", \"<i2\"), (\"y\", \"<i2\"), (\"p\", \"u1\")], align=True)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate all comparison files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evt2 and dat\n",
    "raw_encodings = [\"dat\", \"evt2\", \"evt3\"]\n",
    "for encoding in raw_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    if not os.path.exists(fpath):\n",
    "        print(f\"Generating {fpath}.\")\n",
    "        wizard = Wizard(encoding=encoding)\n",
    "        wizard.save(fpath=fpath, arr=data)\n",
    "\n",
    "# variants of hdf5\n",
    "hdf5_encodings = [\"hdf5\", \"hdf5_lzf\", \"hdf5_gzip\"]\n",
    "for encoding in hdf5_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    if not os.path.exists(fpath):\n",
    "        with h5py.File(fpath, \"w\") as fp:\n",
    "            print(f\"Generating {fpath}.\")\n",
    "            dataset_dict = dict(\n",
    "                name=\"events\",\n",
    "                shape=data.shape,\n",
    "                dtype=data.dtype,\n",
    "                data=data,\n",
    "            )\n",
    "            if encoding == \"hdf5\":\n",
    "                fp.create_dataset(**dataset_dict)\n",
    "            elif encoding == \"hdf5_lzf\":\n",
    "                fp.create_dataset(**dataset_dict, compression=\"lzf\")\n",
    "            elif encoding == \"hdf5_gzip\":\n",
    "                fp.create_dataset(**dataset_dict, compression=\"gzip\")\n",
    "\n",
    "# numpy\n",
    "fpath = get_fpath(\"numpy\")\n",
    "if not os.path.exists(fpath):\n",
    "    print(f\"Generating {fpath}.\")\n",
    "    np.save(fpath, data, allow_pickle=True)\n",
    "\n",
    "# brotli\n",
    "fpath = get_fpath(\"brotli\")\n",
    "if not os.path.exists(fpath):\n",
    "    print(f\"Generating {fpath}.\")\n",
    "    with open(fpath + \".tmp\", \"wb\") as out_file:\n",
    "        with open(get_fpath(\"dat\"), \"rb\") as in_file:\n",
    "            buff = in_file.read()\n",
    "            cnt, i = 0, 0\n",
    "            while cnt < 3:\n",
    "                cnt += 1 if buff[i] == 0x0A else 0\n",
    "                i += 1\n",
    "            out_file.write(buff[i:])\n",
    "    with open(fpath, \"wb\") as out_file:\n",
    "        with open(fpath + \".tmp\", \"rb\") as in_file:\n",
    "            in_file.read(2)\n",
    "            out_file.write(brotli.compress(in_file.read(), quality=5))\n",
    "    os.remove(fpath + \".tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPEAT = 10\n",
    "get_fsize_MB = lambda fpath: round(fpath.stat().st_size / (1024 * 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evt2, evt3, dat\n",
    "print(\"Benchmarking expelliarmus.\")\n",
    "raw_times = []\n",
    "raw_sizes = []\n",
    "for encoding in raw_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    wizard = Wizard(encoding)\n",
    "    wizard.set_file(fpath)\n",
    "    raw_times.append(timeit.timeit(lambda: wizard.read(fpath), number=REPEAT) / REPEAT)\n",
    "    raw_sizes.append(get_fsize_MB(Path(fpath)))\n",
    "\n",
    "# hdf5 variants\n",
    "print(\"Benchmarking HDF5.\")\n",
    "hdf5_times = []\n",
    "hdf5_sizes = []\n",
    "for encoding in hdf5_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    fp = h5py.File(fpath)\n",
    "    hdf5_times.append(timeit.timeit(lambda: fp[\"events\"][:], number=REPEAT) / REPEAT)\n",
    "    fp.close()\n",
    "    hdf5_sizes.append(get_fsize_MB(Path(fpath)))\n",
    "\n",
    "# numpy\n",
    "print(\"Benchmarking NumPy.\")\n",
    "fpath = get_fpath(\"numpy\")\n",
    "numpy_time = timeit.timeit(lambda: np.load(fpath), number=REPEAT) / REPEAT\n",
    "numpy_size = get_fsize_MB(Path(fpath))\n",
    "\n",
    "# aedat4\n",
    "print(\"Benchmarking AEDAT.\")\n",
    "fpath = get_fpath(\"aedat\")\n",
    "read_aedat = lambda: [packet[\"events\"] for packet in aedat.Decoder(fpath) if \"events\" in packet]\n",
    "aedat_time = timeit.timeit(read_aedat, number=REPEAT)/ REPEAT\n",
    "aedat_size = get_fsize_MB(Path(fpath))\n",
    "\n",
    "# eventstream\n",
    "print(\"Benchmarking eventstream.\")\n",
    "fpath = get_fpath(\"eventstream\")\n",
    "es_time = timeit.timeit(lambda: loris.read_file(fpath), number=REPEAT) / REPEAT\n",
    "es_size = get_fsize_MB(Path(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brotli\n",
    "print(\"Benchmarking brotli.\")\n",
    "fpath = get_fpath(\"brotli\")\n",
    "dtype = np.dtype([(\"t\", \"<i8\"), (\"x\", \"<i2\"), (\"y\", \"<i2\"), (\"p\", \"u1\")])\n",
    "\n",
    "\n",
    "def brotli_read():\n",
    "    # Reading to a numpy buffer the data.\n",
    "    with open(fpath, \"rb\") as fp:\n",
    "        np_buff = np.frombuffer(\n",
    "            brotli.decompress(fp.read()), dtype=np.uint64\n",
    "        )  # , align=True)\n",
    "\n",
    "    # Creating the structured NumPy array.\n",
    "    arr = np.empty(len(np_buff), dtype=dtype)\n",
    "\n",
    "    # Decoding the buffer.\n",
    "    arr[\"t\"] = np_buff & 0xFFFFFFFF  # 32 bits\n",
    "    arr[\"x\"] = (np_buff >> (64 - 32)) & 0x3FFF  # 14 bits\n",
    "    arr[\"y\"] = (np_buff >> (64 - (32 + 14))) & 0x3FFF  # 14 bits\n",
    "    arr[\"p\"] = np_buff >> (64 - (32 + 28))\n",
    "\n",
    "\n",
    "brotli_time = timeit.timeit(brotli_read, number=REPEAT) / REPEAT\n",
    "brotli_size = get_fsize_MB(Path(fpath))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Encoding\": raw_encodings\n",
    "        + hdf5_encodings\n",
    "        + [\"numpy\", \"aedat4\", \"eventstream\", \"dat/brotli\"],\n",
    "        \"Framework\": [\"expelliarmus\"] * len(raw_encodings)\n",
    "        + [\"h5py\"] * len(hdf5_encodings)\n",
    "        + [\"numpy\", \"aedat\", \"loris\", \"expelliarmus/brotli\"],\n",
    "        \"Read time [s]\": raw_times\n",
    "        + hdf5_times\n",
    "        + [numpy_time, aedat_time, es_time, brotli_time],\n",
    "        \"File size [MB]\": raw_sizes\n",
    "        + hdf5_sizes\n",
    "        + [numpy_size, aedat_size, es_size, brotli_size],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot results\n",
    "\n",
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "\n",
    "title = f\"Reading the same {int(len(data)/1e6)} million events from different files.\"\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"Read time [s]\",\n",
    "    y=\"File size [MB]\",\n",
    "    color=\"Framework\",\n",
    "    symbol=\"Encoding\",\n",
    "    title=title,\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "fig.update_traces(marker_size=13)\n",
    "fig.write_image(\"file_read_benchmark.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c00e5e7c7a569083cb991dfa106f557879cc0d1d84bf5b9d92fbb6bf680d358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
