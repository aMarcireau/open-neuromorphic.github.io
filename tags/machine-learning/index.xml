<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Open Neuromorphic</title><link>https://open-neuromorphic.org/tags/machine-learning/</link><description>Recent content in machine learning on Open Neuromorphic</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 02 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://open-neuromorphic.org/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Spiking neurons: a digital hardware implementation</title><link>https://open-neuromorphic.org/p/spiking-neurons-a-digital-hardware-implementation/</link><pubDate>Mon, 02 Jan 2023 00:00:00 +0000</pubDate><guid>https://open-neuromorphic.org/p/spiking-neurons-a-digital-hardware-implementation/</guid><description>&lt;img src="https://open-neuromorphic.org/p/spiking-neurons-a-digital-hardware-implementation/loihi.png" alt="Featured image of post Spiking neurons: a digital hardware implementation" />Spiking neurons In this article, we will try to model a layer of Leaky Integrate and Fire (LIF) spiking neurons using digital hardware: registers, memories, adders and so on. To do so, we will consider a single output neuron connected to multiple input neurons from a previous layer.
In a Spiking Neural Network (SNN), neurons communicate by means of spikes: these activation voltages are then converted to currents through the synapses, charging the membrane potential of the destination neuron.</description></item></channel></rss>